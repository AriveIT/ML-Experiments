{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56153af5",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e73e0d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random # for weighted probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68351aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ef748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing(as_frame=True) # Import data set as a data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b673af",
   "metadata": {},
   "source": [
    "### Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fab85d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GA:\n",
    "    \n",
    "    def __init__(self, fitness, data, target, max_generations, mutation_chance, population_size, n_features, min_exponent=0, max_exponent=1):\n",
    "        self.fitness = fitness # fitness takes an encoding, data (X) and target (y) which are dataframes\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.max_generations = max_generations\n",
    "        self.mutation_chance = mutation_chance\n",
    "        self.min_exponent = min_exponent\n",
    "        self.max_exponent = max_exponent\n",
    "        self.population_size = population_size\n",
    "        self.n_features = n_features\n",
    "\n",
    "    def run(self):\n",
    "        max_weight = -np.inf\n",
    "        best_individual = None\n",
    "        population = self.get_initial_population()\n",
    "\n",
    "        for i in range(self.max_generations):\n",
    "            weights = self.weighted_by(population)\n",
    "\n",
    "            # save best individual so far. Since entire population is currently overwritten each generation,\n",
    "            # we might lose the best individual. This is kind of a hacky fix\n",
    "            cur_max = np.max(weights)\n",
    "            if cur_max > max_weight:\n",
    "                max_weight = cur_max\n",
    "                best_individual = population[np.argmax(weights)]\n",
    "            \n",
    "            population = self.get_next_generation(population, weights)\n",
    "        \n",
    "        return best_individual, max_weight\n",
    "\n",
    "    # returns fitness of each individual in the population\n",
    "    # NOTE weighting is not normalized (it is done implicitly by random.choices)\n",
    "    def weighted_by(self, population):\n",
    "\n",
    "        if self.fitness is None:\n",
    "            weights = np.ones(self.population_size)\n",
    "        else:\n",
    "            weights = np.array([self.fitness(individual, self.data, self.target) for individual in population])\n",
    "\n",
    "        return weights\n",
    "\n",
    "    # add/subtract 1 to a couple indices? idk what would be best\n",
    "    # for now, just mutating one index\n",
    "    def mutate(self, child):\n",
    "        idx = np.random.randint(self.n_features)\n",
    "\n",
    "        if child[idx] == self.min_exponent:\n",
    "            child[idx] += 1\n",
    "        elif child[idx] == self.max_exponent:\n",
    "            child[idx] -= 1\n",
    "        else:\n",
    "            child[idx] += np.random.choice([1, -1])\n",
    "\n",
    "        return child\n",
    "\n",
    "    # given a population and weights, gives the next generation\n",
    "    # what generation/population model should we use?\n",
    "    def get_next_generation(self, population, weights):\n",
    "        next_population = None\n",
    "\n",
    "        # replace entire population (for now)\n",
    "        for i in range(self.population_size):\n",
    "\n",
    "            # random.choices returns list with one element which is the np array (the selected individual)\n",
    "            # [0] to just get the np array\n",
    "            parent1 = random.choices(population, weights)[0] # weighted probability (choices should do the normalization for us?)\n",
    "            parent2 = random.choices(population, weights)[0]\n",
    "            child = self.reproduce(parent1, parent2)\n",
    "\n",
    "            if np.random.random() < self.mutation_chance:\n",
    "                child = self.mutate(child)\n",
    "            \n",
    "            if next_population is None:\n",
    "                next_population = child.reshape((1, self.n_features))\n",
    "            else:\n",
    "                # child has to be 2d to append to 2d array (hence reshape)\n",
    "                next_population = np.append(next_population, child.reshape((1, self.n_features)), axis=0)\n",
    "\n",
    "        return next_population\n",
    "\n",
    "    # parents are 1d array w lengths = number of features\n",
    "    def reproduce(self, parent1, parent2):\n",
    "        idx = np.random.randint(self.n_features)\n",
    "        child = np.concatenate((parent1[:idx], parent2[idx:]))\n",
    "        return child\n",
    "\n",
    "    # min and max degree are inclusive\n",
    "    def get_initial_population(self):\n",
    "        return np.random.randint(self.min_exponent, self.max_exponent + 1, (self.population_size, self.n_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21eff9e",
   "metadata": {},
   "source": [
    "### Fitness Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb254a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't have a great motivation for keeping the fitnees_function separate from the GA class other than it\n",
    "# makes it easier to test different fitness functions should we choose to experiment\n",
    "\n",
    "# encoding describes the exponent of each feature in our new term\n",
    "# ex: if our encoding is [1, -1, 0] and our data is [x, y, z] then our new term is x^1 * y^-1 * z^0 = x/y\n",
    "def fitness_function(encoding, data, target):\n",
    "\n",
    "    # create new term\n",
    "    exp_data = np.power(data, encoding)\n",
    "    term = np.prod(exp_data, axis=1) # multiply across rows\n",
    "    \n",
    "    # have to make a copy since we're doing calling this in parallel from a list comprehension\n",
    "    # (overwriting it each time would create a race condition I think maybe)\n",
    "    new_data = data.copy()\n",
    "    new_data[\"GA_term\"] = term\n",
    "\n",
    "    # evaluate term\n",
    "    reg = LinearRegression().fit(new_data, target)\n",
    "    fitness = reg.score(new_data, target)  # R-squared\n",
    "\n",
    "    # MSE is another option\n",
    "    # predictions = reg.predict(new_data)\n",
    "    # fitness = mean_squared_error(target, predictions)\n",
    "\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e31eb5",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2fe1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get testing and training splits\n",
    "train_set, test_set = train_test_split(housing.frame, test_size=0.2, random_state=42)\n",
    "\n",
    "train_X = train_set.drop(columns=\"MedHouseVal\")\n",
    "train_y = train_set[\"MedHouseVal\"]\n",
    "\n",
    "test_X = test_set.drop(columns=\"MedHouseVal\")\n",
    "test_y = test_set[\"MedHouseVal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f68b64e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6189544423975755"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can play around with the encoding to get fitness of different terms/individuals\n",
    "encoding = np.array([0, 0, -1, 1, 0, 0, 0, 0]) # bedrooms / room\n",
    "# encoding = np.array([0, 0, 0, 0, 0, 0, 0, 0]) # original regression with no new terms\n",
    "\n",
    "fitness_function(encoding, train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f2288af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1,  1, -1,  1,  1, -2,  2, -2]), 0.664987464039654)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ga = GA(fitness_function,\n",
    "        train_X,\n",
    "        train_y,\n",
    "        max_generations = 100,\n",
    "        mutation_chance = 0.05,\n",
    "        population_size = 20,\n",
    "        n_features = 8,\n",
    "        min_exponent=-2,\n",
    "        max_exponent=2)\n",
    "ga.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2998daa1",
   "metadata": {},
   "source": [
    "### TODO:\n",
    " - Experiment with different population/generation models\n",
    " - Experiment with different mutation functions\n",
    " - Add max degree restriction to force simpler terms?\n",
    " - Create pipeline to keep finding new terms until $R^2_{adjusted}$ decreases?\n",
    " - Compare to other searches?\n",
    " - Test on other tabular datasets?\n",
    " - Test on other ML algorithms? (different from linear regression)\n",
    " - Add termination case for when improvement stops?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44368bec",
   "metadata": {},
   "source": [
    "### Compare to dummy (selecting terms randomly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "875ccb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  0  0  0  0 -2  1 -2] 0.6686303952477901\n"
     ]
    }
   ],
   "source": [
    "total_individuals = ga.max_generations * ga.population_size\n",
    "\n",
    "individuals = np.random.randint(ga.min_exponent, ga.max_exponent + 1, (total_individuals, ga.n_features))\n",
    "weights = np.array([fitness_function(individual, ga.data, ga.target) for individual in individuals])\n",
    "\n",
    "idx = np.argmax(weights)\n",
    "print(individuals[idx], weights[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f96a1c",
   "metadata": {},
   "source": [
    "yikes random search does just as well, if not better..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
